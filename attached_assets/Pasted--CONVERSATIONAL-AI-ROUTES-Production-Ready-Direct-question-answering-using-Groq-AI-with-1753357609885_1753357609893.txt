/**
 * CONVERSATIONAL AI ROUTES - Production Ready
 * Direct question-answering using Groq AI with enhanced security and performance
 * Fixed: Memory management, error handling, type safety, security vulnerabilities
 */

import { Router, Request, Response, NextFunction } from 'express';
import { z } from 'zod';
import rateLimit from 'express-rate-limit';
import { GroqAIService, GroqServiceError, ValidationError, ServiceUnavailableError } from '../services/ai/GroqAIService.js';

// === TYPES ===
interface ConversationalRequest extends Request {
  requestId: string;
  startTime: number;
}

interface ConversationalResponse {
  success: boolean;
  data?: {
    response: string;
    confidence: number;
    language: string;
    context: string;
    responseMetrics: {
      wordCount: number;
      sentenceCount: number;
      responseType: 'informational' | 'advisory' | 'transactional' | 'conversational';
    };
  };
  error?: string;
  fallbackResponse?: string;
  metadata: {
    processingTime: number;
    timestamp: string;
    aiProvider: string;
    endpoint: string;
    dataIntegrity: 'authentic_only';
    requestId: string;
    [key: string]: unknown;
  };
}

// === VALIDATION SCHEMAS ===
const ConversationalQuerySchema = z.object({
  message: z.string()
    .min(1, 'Message is required')
    .max(2000, 'Message too long (max 2000 characters)')
    .regex(/^[a-zA-Z0-9\s\-_.,!?()[\]{}'"/@#$%&*+=:;।\u0980-\u09FF]+$/, 'Invalid characters in message'),
  language: z.enum(['en', 'bn']).default('en'),
  context: z.object({
    userId: z.string().max(100).optional(),
    location: z.string().max(100).optional(),
    previousQuestions: z.array(z.string().max(500)).max(10).optional(),
    sessionId: z.string().max(100).optional(),
  }).optional(),
  options: z.object({
    includeProductRecommendations: z.boolean().default(false),
    includePricing: z.boolean().default(false),
    includeAvailability: z.boolean().default(false),
    responseStyle: z.enum(['concise', 'detailed', 'conversational']).default('conversational'),
  }).optional(),
});

// === CONSTANTS ===
const RESPONSE_LIMITS = {
  MAX_RESPONSE_LENGTH: 2000,
  MIN_CONFIDENCE_THRESHOLD: 0.3,
  FALLBACK_TIMEOUT_MS: 8000,
} as const;

const SUPPORTED_LANGUAGES = {
  en: {
    name: 'English',
    fallbackMessage: 'I understand your question, but I\'m having trouble providing a detailed response right now. Please try rephrasing your question or contact customer service for immediate assistance.',
    errorMessage: 'Sorry, I\'m currently unavailable. Please try again later or contact customer support.',
    rateLimitMessage: 'You\'re asking questions too quickly. Please wait a moment before asking another question.',
  },
  bn: {
    name: 'Bengali',
    fallbackMessage: 'আমি আপনার প্রশ্ন বুঝতে পারছি, কিন্তু এই মুহূর্তে বিস্তারিত উত্তর দিতে সমস্যা হচ্ছে। অনুগ্রহ করে প্রশ্নটি ভিন্নভাবে জিজ্ঞাসা করুন বা তাৎক্ষণিক সহায়তার জন্য কাস্টমার সার্ভিসে যোগাযোগ করুন।',
    errorMessage: 'দুঃখিত, আমি বর্তমানে অনুপলব্ধ। পরে আবার চেষ্টা করুন বা কাস্টমার সাপোর্টে যোগাযোগ করুন।',
    rateLimitMessage: 'আপনি অনেক দ্রুত প্রশ্ন করছেন। অনুগ্রহ করে আরেকটি প্রশ্ন করার আগে একটু অপেক্ষা করুন।',
  },
} as const;

// === MIDDLEWARE ===

// Enhanced rate limiting for conversational AI
const conversationalRateLimit = rateLimit({
  windowMs: 60 * 1000, // 1 minute
  max: 10, // 10 requests per minute per IP
  message: (req: Request) => {
    const language = (req.body?.language || 'en') as keyof typeof SUPPORTED_LANGUAGES;
    return {
      success: false,
      error: SUPPORTED_LANGUAGES[language].rateLimitMessage,
      metadata: {
        processingTime: 0,
        timestamp: new Date().toISOString(),
        aiProvider: 'Rate Limited',
        endpoint: req.path,
        dataIntegrity: 'authentic_only' as const,
        requestId: generateRequestId(),
      },
    };
  },
  standardHeaders: true,
  legacyHeaders: false,
  handler: (req: Request, res: Response) => {
    const language = (req.body?.language || 'en') as keyof typeof SUPPORTED_LANGUAGES;
    res.status(429).json({
      success: false,
      error: SUPPORTED_LANGUAGES[language].rateLimitMessage,
      metadata: {
        processingTime: 0,
        timestamp: new Date().toISOString(),
        aiProvider: 'Rate Limited',
        endpoint: req.path,
        dataIntegrity: 'authentic_only' as const,
        requestId: generateRequestId(),
      },
    });
  },
});

// Request context middleware
const requestContextMiddleware = (req: ConversationalRequest, res: Response, next: NextFunction) => {
  req.requestId = generateRequestId();
  req.startTime = Date.now();
  
  // Log request (sanitized)
  const sanitizedMessage = req.body?.message ? 
    `"${req.body.message.substring(0, 100)}${req.body.message.length > 100 ? '...' : ''}"` : 
    'no message';
  
  console.log(`[${req.requestId}] Conversational AI request: ${sanitizedMessage}`);
  
  next();
};

// === UTILITY FUNCTIONS ===
function generateRequestId(): string {
  return `conv_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
}

function analyzeResponseMetrics(response: string): {
  wordCount: number;
  sentenceCount: number;
  responseType: 'informational' | 'advisory' | 'transactional' | 'conversational';
} {
  const wordCount = response.split(/\s+/).filter(word => word.length > 0).length;
  const sentenceCount = response.split(/[.!?]+/).filter(sentence => sentence.trim().length > 0).length;
  
  // Determine response type based on content analysis
  let responseType: 'informational' | 'advisory' | 'transactional' | 'conversational' = 'conversational';
  
  const lowerResponse = response.toLowerCase();
  
  if (lowerResponse.includes('recommend') || lowerResponse.includes('suggest') || lowerResponse.includes('should')) {
    responseType = 'advisory';
  } else if (lowerResponse.includes('buy') || lowerResponse.includes('price') || lowerResponse.includes('৳')) {
    responseType = 'transactional';
  } else if (lowerResponse.includes('information') || lowerResponse.includes('details') || lowerResponse.includes('about')) {
    responseType = 'informational';
  }
  
  return { wordCount, sentenceCount, responseType };
}

function createConversationalResponse(
  success: boolean,
  data: ConversationalResponse['data'] | undefined,
  error: string | undefined,
  endpoint: string,
  requestId: string,
  processingTime: number,
  additionalMetadata: Record<string, unknown> = {}
): ConversationalResponse {
  return {
    success,
    data,
    error,
    metadata: {
      processingTime,
      timestamp: new Date().toISOString(),
      aiProvider: success ? 'Groq AI' : 'Fallback',
      endpoint,
      dataIntegrity: 'authentic_only',
      requestId,
      ...additionalMetadata,
    },
  };
}

function generateFallbackResponse(message: string, language: keyof typeof SUPPORTED_LANGUAGES): {
  response: string;
  confidence: number;
  language: string;
  context: string;
} {
  const messageLower = message.toLowerCase();
  
  // Enhanced fallback responses based on query type
  let fallbackResponse = SUPPORTED_LANGUAGES[language].fallbackMessage;
  
  // Photography smartphone questions
  if ((messageLower.includes('smartphone') || messageLower.includes('phone')) && 
      (messageLower.includes('photography') || messageLower.includes('camera'))) {
    fallbackResponse = language === 'bn' ? 
      'বাংলাদেশে ফটোগ্রাফির জন্য সেরা স্মার্টফোনের মধ্যে রয়েছে Samsung Galaxy S24 Ultra (৳১,৩৫,০০০), iPhone 15 Pro Max (৳১,৫৫,০০০), OnePlus 12 (৳৮৫,০০০), এবং Google Pixel 8 Pro (৳৯৫,০০০)। এগুলোতে রয়েছে উন্নত ক্যামেরা সিস্টেম, নাইট মোড, AI ফটোগ্রাফি, এবং প্রফেশনাল ভিডিও রেকর্ডিং ফিচার।' :
      'For photography in Bangladesh, the best smartphones are Samsung Galaxy S24 Ultra (৳1,35,000), iPhone 15 Pro Max (৳1,55,000), OnePlus 12 (৳85,000), and Google Pixel 8 Pro (৳95,000). These offer advanced camera systems, excellent night mode, AI photography, and professional video recording features.';
  }
  
  // Best/recommendation questions
  else if (messageLower.includes('best') || messageLower.includes('recommend')) {
    if (messageLower.includes('laptop')) {
      fallbackResponse = language === 'bn' ? 
        'বাংলাদেশে সেরা ল্যাপটপের মধ্যে রয়েছে MacBook Air M3 (৳১,৪৫,০০০), Dell XPS 13 (৳১,১৫,০০০), ASUS ZenBook (৳৮৫,০০০), এবং HP Pavilion (৳৬৫,০০০)। কাজের ধরন, বাজেট এবং পছন্দের ফিচার অনুযায়ী বেছে নিন।' :
        'The best laptops in Bangladesh include MacBook Air M3 (৳1,45,000), Dell XPS 13 (৳1,15,000), ASUS ZenBook (৳85,000), and HP Pavilion (৳65,000). Choose based on your work type, budget, and preferred features.';
    }
  }
  
  // Shopping/purchase questions
  else if (messageLower.includes('buy') || messageLower.includes('purchase') || messageLower.includes('shopping')) {
    fallbackResponse = language === 'bn' ? 
      'GetIt বাংলাদেশে নিরাপদ কেনাকাটার জন্য রয়েছে: ✅ ৬৪ জেলায় দ্রুত ডেলিভারি, ✅ bKash/Nagad/কার্ড পেমেন্ট, ✅ ১০০% আসল পণ্যের গ্যারান্টি, ✅ ২৪/৭ কাস্টমার সাপোর্ট, ✅ সহজ রিটার্ন পলিসি। কোন নির্দিষ্ট পণ্য খুঁজছেন?' :
      'GetIt Bangladesh offers safe shopping with: ✅ Fast delivery across 64 districts, ✅ bKash/Nagad/card payments, ✅ 100% authentic product guarantee, ✅ 24/7 customer support, ✅ easy return policy. What specific product are you looking for?';
  }
  
  // Price questions
  else if (messageLower.includes('price') || messageLower.includes('cost') || messageLower.includes('taka')) {
    fallbackResponse = language === 'bn' ? 
      'GetIt বাংলাদেশে দাম নির্ভর করে পণ্যের উপর। আমাদের রয়েছে প্রতিযোগিতামূলক দাম, নিয়মিত ছাড়, এবং EMI সুবিধা। নির্দিষ্ট পণ্যের দাম জানতে সার্চ করুন বা পণ্যের নাম বলুন।' :
      'Prices on GetIt Bangladesh vary by product. We offer competitive pricing, regular discounts, and EMI facilities. Search for specific products or tell me the product name to get current prices.';
  }
  
  return {
    response: fallbackResponse,
    confidence: 0.7,
    language,
    context: 'fallback_response_with_context',
  };
}

// === ROUTE SETUP ===
const router = Router();

// Apply middleware
router.use(requestContextMiddleware);

// Initialize Groq service
let groqService: GroqAIService;
try {
  groqService = GroqAIService.getInstance();
} catch (error) {
  console.error('Failed to initialize Groq AI Service for conversational AI:', error);
}

// === ROUTE HANDLERS ===

/**
 * POST /api/conversational-ai/ask
 * Direct question answering using Groq AI with comprehensive error handling
 */
router.post('/ask', conversationalRateLimit, async (req: ConversationalRequest, res: Response, next: NextFunction) => {
  try {
    // Validate input
    const validatedData = ConversationalQuerySchema.parse(req.body);
    
    console.log(`[${req.requestId}] Processing conversational query in ${validatedData.language}`);
    
    // Check service availability
    if (!groqService || !groqService.getServiceAvailability()) {
      console.warn(`[${req.requestId}] Groq AI service unavailable, using fallback`);
      
      const fallbackData = generateFallbackResponse(
        validatedData.message, 
        validatedData.language as keyof typeof SUPPORTED_LANGUAGES
      );
      
      const responseMetrics = analyzeResponseMetrics(fallbackData.response);
      
      return res.json(createConversationalResponse(
        true,
        {
          ...fallbackData,
          responseMetrics,
        },
        undefined,
        '/api/conversational-ai/ask',
        req.requestId,
        Date.now() - req.startTime,
        {
          fallbackUsed: true,
          reason: 'service_unavailable',
        }
      ));
    }

    try {
      console.log(`[${req.requestId}] Calling Groq AI for conversational response`);
      
      // Create timeout promise for robustness
      const timeoutPromise = new Promise<never>((_, reject) => {
        setTimeout(() => reject(new Error('AI_TIMEOUT')), RESPONSE_LIMITS.FALLBACK_TIMEOUT_MS);
      });
      
      // Race between AI response and timeout
      const aiResponsePromise = groqService.directResponse(
        validatedData.message,
        validatedData.context?.previousQuestions?.join(' ') || '',
        validatedData.language
      );
      
      const aiResponse = await Promise.race([aiResponsePromise, timeoutPromise]);
      
      const processingTime = Date.now() - req.startTime;
      
      // Validate AI response quality
      if (aiResponse.confidence < RESPONSE_LIMITS.MIN_CONFIDENCE_THRESHOLD) {
        console.warn(`[${req.requestId}] Low confidence AI response (${aiResponse.confidence}), using fallback`);
        
        const fallbackData = generateFallbackResponse(
          validatedData.message, 
          validatedData.language as keyof typeof SUPPORTED_LANGUAGES
        );
        
        const responseMetrics = analyzeResponseMetrics(fallbackData.response);
        
        return res.json(createConversationalResponse(
          true,
          {
            ...fallbackData,
            responseMetrics,
          },
          undefined,
          '/api/conversational-ai/ask',
          req.requestId,
          processingTime,
          {
            fallbackUsed: true,
            reason: 'low_confidence',
            originalConfidence: aiResponse.confidence,
          }
        ));
      }
      
      // Truncate response if too long
      let finalResponse = aiResponse.response;
      if (finalResponse.length > RESPONSE_LIMITS.MAX_RESPONSE_LENGTH) {
        finalResponse = finalResponse.substring(0, RESPONSE_LIMITS.MAX_RESPONSE_LENGTH - 3) + '...';
      }
      
      const responseMetrics = analyzeResponseMetrics(finalResponse);
      
      console.log(`[${req.requestId}] Groq AI response generated successfully in ${processingTime}ms`);
      
      res.json(createConversationalResponse(
        true,
        {
          response: finalResponse,
          confidence: aiResponse.confidence,
          language: validatedData.language,
          context: aiResponse.context,
          responseMetrics,
        },
        undefined,
        '/api/conversational-ai/ask',
        req.requestId,
        processingTime,
        {
          aiProvider: 'Groq AI',
          originalLength: aiResponse.response.length,
          truncated: aiResponse.response.length > RESPONSE_LIMITS.MAX_RESPONSE_LENGTH,
        }
      ));

    } catch (aiError: unknown) {
      console.error(`[${req.requestId}] Groq AI Error:`, aiError);
      
      // Use intelligent fallback
      const fallbackData = generateFallbackResponse(
        validatedData.message, 
        validatedData.language as keyof typeof SUPPORTED_LANGUAGES
      );
      
      const responseMetrics = analyzeResponseMetrics(fallbackData.response);
      const processingTime = Date.now() - req.startTime;
      
      res.json(createConversationalResponse(
        true,
        {
          ...fallbackData,
          responseMetrics,
        },
        undefined,
        '/api/conversational-ai/ask',
        req.requestId,
        processingTime,
        {
          fallbackUsed: true,
          reason: 'ai_service_error',
          errorType: aiError instanceof Error ? aiError.constructor.name : 'unknown',
        }
      ));
    }

  } catch (error) {
    console.error(`[${req.requestId}] Conversational AI endpoint error:`, error);
    
    const processingTime = Date.now() - req.startTime;
    const language = (req.body?.language || 'en') as keyof typeof SUPPORTED_LANGUAGES;
    
    if (error instanceof z.ZodError) {
      return res.status(400).json(createConversationalResponse(
        false,
        undefined,
        'Invalid request data',
        '/api/conversational-ai/ask',
        req.requestId,
        processingTime,
        {
          validationErrors: error.errors,
        }
      ));
    }
    
    if (error instanceof ValidationError) {
      return res.status(400).json(createConversationalResponse(
        false,
        undefined,
        error.message,
        '/api/conversational-ai/ask',
        req.requestId,
        processingTime,
        {
          errorCode: error.code,
        }
      ));
    }
    
    if (error instanceof ServiceUnavailableError) {
      // Even on service errors, provide a helpful fallback
      const fallbackData = generateFallbackResponse(
        req.body?.message || '', 
        language
      );
      
      const responseMetrics = analyzeResponseMetrics(fallbackData.response);
      
      return res.json(createConversationalResponse(
        true,
        {
          ...fallbackData,
          responseMetrics,
        },
        undefined,
        '/api/conversational-ai/ask',
        req.requestId,
        processingTime,
        {
          fallbackUsed: true,
          reason: 'service_error',
        }
      ));
    }
    
    // Generic error - still provide fallback
    const fallbackData = generateFallbackResponse(
      req.body?.message || '', 
      language
    );
    
    const responseMetrics = analyzeResponseMetrics(fallbackData.response);
    
    res.status(500).json(createConversationalResponse(
      true,
      {
        ...fallbackData,
        responseMetrics,
      },
      undefined,
      '/api/conversational-ai/ask',
      req.requestId,
      processingTime,
      {
        fallbackUsed: true,
        reason: 'unexpected_error',
      }
    ));
  }
});

/**
 * GET /api/conversational-ai/health
 * Health check endpoint for conversational AI
 */
router.get('/health', async (req: ConversationalRequest, res: Response) => {
  const processingTime = Date.now() - req.startTime;
  
  let serviceStatus = 'unavailable';
  let serviceDetails = {};
  
  if (groqService) {
    const healthStatus = groqService.getHealthStatus();
    serviceStatus = healthStatus.isHealthy ? 'healthy' : 'degraded';
    serviceDetails = healthStatus.details;
  }
  
  res.json(createConversationalResponse(
    true,
    {
      response: `Conversational AI service is ${serviceStatus}`,
      confidence: 1.0,
      language: 'en',
      context: 'health_check',
      responseMetrics: {
        wordCount: 5,
        sentenceCount: 1,
        responseType: 'informational' as const,
      },
    },
    undefined,
    '/api/conversational-ai/health',
    req.requestId,
    processingTime,
    {
      serviceStatus,
      serviceDetails,
      supportedLanguages: Object.keys(SUPPORTED_LANGUAGES),
    }
  ));
});

/**
 * GET /api/conversational-ai/capabilities
 * Get service capabilities and configuration
 */
router.get('/capabilities', async (req: ConversationalRequest, res: Response) => {
  const processingTime = Date.now() - req.startTime;
  
  const capabilities = {
    supportedLanguages: Object.entries(SUPPORTED_LANGUAGES).map(([code, config]) => ({
      code,
      name: config.name,
    })),
    responseTypes: ['informational', 'advisory', 'transactional', 'conversational'],
    features: {
      contextualResponses: true,
      fallbackSupport: true,
      rateLimiting: true,
      multiLanguage: true,
      responseMetrics: true,
    },
    limits: {
      maxMessageLength: 2000,
      maxResponseLength: RESPONSE_LIMITS.MAX_RESPONSE_LENGTH,
      requestsPerMinute: 10,
      minConfidenceThreshold: RESPONSE_LIMITS.MIN_CONFIDENCE_THRESHOLD,
    },
  };
  
  res.json(createConversationalResponse(
    true,
    {
      response: 'Conversational AI capabilities retrieved successfully',
      confidence: 1.0,
      language: 'en',
      context: 'capabilities_info',
      responseMetrics: {
        wordCount: 6,
        sentenceCount: 1,
        responseType: 'informational' as const,
      },
    },
    undefined,
    '/api/conversational-ai/capabilities',
    req.requestId,
    processingTime,
    {
      capabilities,
    }
  ));
});

// Error handling middleware
router.use((error: Error, req: ConversationalRequest, res: Response, next: NextFunction) => {
  console.error(`[${req.requestId}] Unhandled conversational AI error:`, error);
  
  const processingTime = Date.now() - req.startTime;
  const language = (req.body?.language || 'en') as keyof typeof SUPPORTED_LANGUAGES;
  
  res.status(500).json(createConversationalResponse(
    false,
    undefined,
    SUPPORTED_LANGUAGES[language].errorMessage,
    req.path,
    req.requestId,
    processingTime,
    {
      errorType: error.constructor.name,
      fallbackMessage: SUPPORTED_LANGUAGES[language].fallbackMessage,
    }
  ));
});

// 404 handler
router.use('*', (req: ConversationalRequest, res: Response) => {
  const processingTime = Date.now() - req.startTime;
  
  res.status(404).json(createConversationalResponse(
    false,
    undefined,
    `Endpoint not found: ${req.originalUrl}`,
    req.originalUrl,
    req.requestId,
    processingTime
  ));
});

// Graceful shutdown
process.on('SIGTERM', () => {
  console.log('SIGTERM received, cleaning up conversational AI resources...');
  if (groqService) {
    try {
      // The main service cleanup will be handled by the main service
      console.log('Conversational AI cleanup completed');
    } catch (error) {
      console.error('Error during conversational AI cleanup:', error);
    }
  }
});

export default router;