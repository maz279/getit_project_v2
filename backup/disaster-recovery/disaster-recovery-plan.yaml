# Disaster Recovery Plan for GetIt Bangladesh Multi-Vendor E-commerce Platform
# Amazon.com/Shopee.sg-Level Business Continuity and Disaster Recovery

apiVersion: v1
kind: ConfigMap
metadata:
  name: disaster-recovery-plan
  namespace: production
  labels:
    app: disaster-recovery
    tier: operations
    project: getit-bangladesh
data:
  # =============================================================================
  # DISASTER RECOVERY CONFIGURATION
  # =============================================================================
  
  recovery-plan.yaml: |
    # GetIt Bangladesh Disaster Recovery Plan
    # Version: 2.0.0
    # Last Updated: 2025-01-12
    
    disaster_recovery:
      plan_version: "2.0.0"
      last_updated: "2025-01-12"
      responsible_team: "GetIt Bangladesh DevOps Team"
      contact_email: "devops@getit.com.bd"
      emergency_phone: "+880-1700-000000"
      
      # Recovery Time Objectives (RTO) and Recovery Point Objectives (RPO)
      objectives:
        critical_services:
          payment_processing:
            rto: "15 minutes"
            rpo: "5 minutes"
            priority: 1
          order_management:
            rto: "30 minutes"
            rpo: "15 minutes"
            priority: 2
          user_authentication:
            rto: "30 minutes"
            rpo: "15 minutes"
            priority: 2
          product_catalog:
            rto: "1 hour"
            rpo: "30 minutes"
            priority: 3
        
        supporting_services:
          search_functionality:
            rto: "2 hours"
            rpo: "1 hour"
            priority: 4
          analytics_reporting:
            rto: "4 hours"
            rpo: "2 hours"
            priority: 5
          marketing_tools:
            rto: "8 hours"
            rpo: "4 hours"
            priority: 6
      
      # Disaster Scenarios
      scenarios:
        - name: "Complete Data Center Outage"
          probability: "Low"
          impact: "Critical"
          recovery_strategy: "Multi-region failover"
          estimated_rto: "30 minutes"
          
        - name: "Database Corruption"
          probability: "Medium"
          impact: "High"
          recovery_strategy: "Point-in-time recovery from backups"
          estimated_rto: "2 hours"
          
        - name: "Application Server Failure"
          probability: "High"
          impact: "Medium"
          recovery_strategy: "Auto-scaling and load balancing"
          estimated_rto: "5 minutes"
          
        - name: "Network Partition"
          probability: "Medium"
          impact: "High"
          recovery_strategy: "Traffic rerouting via CDN"
          estimated_rto: "15 minutes"
          
        - name: "Cyber Security Incident"
          probability: "Medium"
          impact: "Critical"
          recovery_strategy: "Incident response and clean recovery"
          estimated_rto: "4 hours"
          
        - name: "Natural Disaster (Bangladesh specific)"
          probability: "Medium"
          impact: "Critical"
          recovery_strategy: "Geographic distribution and cloud failover"
          estimated_rto: "1 hour"
      
      # Recovery Procedures
      procedures:
        immediate_response:
          - "Activate incident response team"
          - "Assess scope and impact of disaster"
          - "Notify stakeholders and customers"
          - "Execute appropriate recovery procedure"
          - "Monitor recovery progress"
          
        database_recovery:
          - "Stop all write operations to affected databases"
          - "Identify latest consistent backup"
          - "Restore database from backup to standby instance"
          - "Verify data integrity and consistency"
          - "Switch application traffic to recovered database"
          - "Monitor application performance and data consistency"
          
        application_recovery:
          - "Scale application containers horizontally"
          - "Deploy to alternative availability zones"
          - "Update load balancer configuration"
          - "Verify application functionality"
          - "Monitor performance metrics"
          
        network_recovery:
          - "Identify failed network components"
          - "Reroute traffic through alternative paths"
          - "Update DNS configurations if necessary"
          - "Verify connectivity and latency"
          - "Monitor network performance"
      
      # Bangladesh Specific Considerations
      bangladesh_considerations:
        mobile_banking_integration:
          - "Ensure bKash, Nagad, Rocket failover mechanisms"
          - "Coordinate with mobile banking providers"
          - "Maintain backup payment gateway configurations"
          
        local_courier_services:
          - "Pathao and Paperfly backup integrations"
          - "Alternative courier service configurations"
          - "Local delivery partner coordination"
          
        cultural_factors:
          - "Consider prayer times for maintenance windows"
          - "Account for festival seasons and high traffic"
          - "Bengali language support continuity"
          
        regulatory_compliance:
          - "Bangladesh Bank payment regulations"
          - "Data residency requirements"
          - "Local privacy law compliance"
      
      # Communication Plan
      communication:
        internal_team:
          primary: "Slack #incident-response"
          secondary: "WhatsApp group: GetIt Emergency"
          escalation: "Direct calls to team leads"
          
        external_stakeholders:
          customers: "Status page updates + email notifications"
          vendors: "Vendor portal notifications"
          partners: "Direct email and phone calls"
          regulators: "Formal incident reports as required"
          
        media_response:
          spokesperson: "CTO or designated representative"
          approved_statements: "Pre-approved incident response templates"
          social_media: "Official GetIt Bangladesh accounts only"
      
      # Recovery Resources
      resources:
        backup_locations:
          primary: "AWS ap-southeast-1 (Singapore)"
          secondary: "AWS ap-south-1 (Mumbai)"
          tertiary: "Local Bangladesh data center"
          
        recovery_infrastructure:
          kubernetes_clusters:
            - "Production cluster (Singapore)"
            - "DR cluster (Mumbai)"
            - "Local failover (Dhaka)"
          
          databases:
            - "PostgreSQL primary (Singapore)"
            - "PostgreSQL standby (Mumbai)"
            - "Redis cluster with replication"
            
          storage:
            - "S3 cross-region replication"
            - "EFS backup and restore"
            - "Local storage backup"
      
      # Testing and Validation
      testing:
        schedule:
          disaster_recovery_drill: "Quarterly"
          backup_restoration: "Monthly"
          failover_testing: "Weekly"
          communication_test: "Monthly"
          
        scenarios_to_test:
          - "Complete application failover"
          - "Database point-in-time recovery"
          - "Network partition handling"
          - "Payment gateway failover"
          - "Mobile banking service interruption"
          
        success_criteria:
          - "RTO objectives met"
          - "RPO objectives met"
          - "Data integrity maintained"
          - "Zero data loss for critical transactions"
          - "Communication plan executed successfully"
      
      # Monitoring and Alerting
      monitoring:
        health_checks:
          - "Application endpoint health"
          - "Database connectivity and performance"
          - "Payment gateway status"
          - "Bangladesh mobile banking APIs"
          - "Courier service integrations"
          
        automated_failover:
          - "Database replica promotion"
          - "Application auto-scaling"
          - "Traffic routing via load balancer"
          - "DNS failover configuration"
          
        alerting_thresholds:
          critical: "Service unavailable for > 5 minutes"
          warning: "Performance degradation > 30 seconds"
          info: "Backup failures or configuration changes"

  # =============================================================================
  # RUNBOOK PROCEDURES
  # =============================================================================
  
  runbook-procedures.md: |
    # GetIt Bangladesh Disaster Recovery Runbook
    
    ## Emergency Contacts
    
    ### Primary Team
    - **DevOps Lead**: +880-1700-000001
    - **CTO**: +880-1700-000002
    - **Database Admin**: +880-1700-000003
    - **Security Lead**: +880-1700-000004
    
    ### External Partners
    - **AWS Support**: +1-206-266-4064
    - **CloudFlare Support**: +1-650-319-8930
    - **bKash Technical**: +880-16247-15645
    - **Nagad Support**: +880-1700-019999
    
    ## Procedure 1: Database Recovery
    
    ### Prerequisites
    - Access to AWS console
    - Database backup credentials
    - kubectl access to production cluster
    
    ### Steps
    1. **Identify the Issue**
       ```bash
       kubectl get pods -n production | grep postgres
       kubectl logs deployment/postgres -n production
       ```
    
    2. **Stop Write Operations**
       ```bash
       kubectl scale deployment backend --replicas=0 -n production
       ```
    
    3. **Identify Latest Backup**
       ```bash
       aws s3 ls s3://getit-bangladesh-backups/postgres/daily/ --region ap-southeast-1
       ```
    
    4. **Restore Database**
       ```bash
       # Download latest backup
       LATEST_BACKUP=$(aws s3 ls s3://getit-bangladesh-backups/postgres/daily/ | sort | tail -n 1 | awk '{print $4}')
       aws s3 cp s3://getit-bangladesh-backups/postgres/daily/$LATEST_BACKUP /tmp/
       
       # Restore to standby instance
       gunzip /tmp/$LATEST_BACKUP
       pg_restore -h standby-postgres -U postgres -d getit_production /tmp/${LATEST_BACKUP%.gz}
       ```
    
    5. **Verify Data Integrity**
       ```bash
       psql -h standby-postgres -U postgres -d getit_production -c "SELECT COUNT(*) FROM users;"
       psql -h standby-postgres -U postgres -d getit_production -c "SELECT COUNT(*) FROM orders WHERE created_at > NOW() - INTERVAL '24 hours';"
       ```
    
    6. **Switch Traffic**
       ```bash
       kubectl patch configmap database-config -n production -p '{"data":{"database-host":"standby-postgres"}}'
       kubectl rollout restart deployment/backend -n production
       ```
    
    ## Procedure 2: Application Failover
    
    ### Steps
    1. **Scale Up Replicas**
       ```bash
       kubectl scale deployment backend --replicas=10 -n production
       kubectl scale deployment frontend --replicas=6 -n production
       ```
    
    2. **Deploy to Secondary Region**
       ```bash
       kubectl config use-context mumbai-cluster
       kubectl apply -f k8s/deployments/ -n production
       ```
    
    3. **Update DNS**
       ```bash
       # Update Route53 or CloudFlare DNS
       # Point getit.com.bd to Mumbai load balancer
       ```
    
    ## Procedure 3: Payment Gateway Failover
    
    ### Steps
    1. **Check Primary Gateway Status**
       ```bash
       curl -f https://api.getit.com.bd/api/v1/payments/health
       ```
    
    2. **Switch to Backup Gateway**
       ```bash
       kubectl patch configmap payment-config -n production -p '{"data":{"primary-gateway":"backup-gateway"}}'
       ```
    
    3. **Verify Mobile Banking**
       ```bash
       # Test bKash
       curl -X POST https://api.getit.com.bd/api/v1/payments/bkash/test
       
       # Test Nagad
       curl -X POST https://api.getit.com.bd/api/v1/payments/nagad/test
       
       # Test Rocket
       curl -X POST https://api.getit.com.bd/api/v1/payments/rocket/test
       ```
    
    ## Procedure 4: Communication During Incident
    
    ### Internal Communication
    1. **Slack Alert**
       ```
       @channel INCIDENT: [SEVERITY] - [BRIEF DESCRIPTION]
       Impact: [CUSTOMER IMPACT]
       ETA: [ESTIMATED RESOLUTION TIME]
       Lead: [INCIDENT COMMANDER]
       ```
    
    2. **Status Updates**
       - Update every 15 minutes during critical incidents
       - Update every 30 minutes during major incidents
       - Include: current status, actions taken, next steps, ETA
    
    ### External Communication
    1. **Customer Notification**
       ```
       Subject: GetIt Bangladesh Service Update
       
       We are currently experiencing [ISSUE DESCRIPTION].
       Impact: [CUSTOMER IMPACT]
       We are working to resolve this and estimate normal service will resume by [TIME].
       Updates: https://status.getit.com.bd
       ```
    
    2. **Social Media**
       ```
       We're aware of service issues affecting some users.
       Our team is working on a fix. Updates: https://status.getit.com.bd
       #GetItBangladesh #ServiceUpdate
       ```
    
    ## Bangladesh Specific Procedures
    
    ### Mobile Banking Integration Issues
    1. **bKash Service Interruption**
       - Contact bKash technical support
       - Enable backup payment methods
       - Notify customers via SMS and app notification
    
    2. **Nagad/Rocket Issues**
       - Similar process as bKash
       - Update payment method priorities
       - Monitor transaction success rates
    
    ### Cultural Considerations
    1. **Prayer Time Maintenance**
       - Schedule non-critical maintenance during prayer times
       - Ensure customer notifications respect prayer schedules
    
    2. **Festival Season**
       - Increase monitoring during Eid, Pohela Boishakh
       - Have additional staff on standby
       - Prepare for traffic spikes
    
    ## Recovery Verification Checklist
    
    ### Post-Recovery Steps
    - [ ] All services responding to health checks
    - [ ] Database connections stable
    - [ ] Payment gateways functional
    - [ ] Mobile banking integrations working
    - [ ] Courier service APIs responsive
    - [ ] Monitoring and alerting operational
    - [ ] Performance metrics within normal ranges
    - [ ] Customer notification sent (if applicable)
    - [ ] Post-incident review scheduled
    
    ### Success Criteria
    - [ ] RTO objectives met
    - [ ] RPO objectives met
    - [ ] Zero data loss for critical transactions
    - [ ] Customer impact minimized
    - [ ] All stakeholders informed
    - [ ] Root cause identified (if applicable)

  # =============================================================================
  # AUTOMATION SCRIPTS
  # =============================================================================
  
  failover-automation.sh: |
    #!/bin/bash
    # GetIt Bangladesh Automated Failover Script
    
    set -euo pipefail
    
    # Configuration
    PRIMARY_CLUSTER="singapore-cluster"
    SECONDARY_CLUSTER="mumbai-cluster"
    NAMESPACE="production"
    HEALTH_ENDPOINT="https://api.getit.com.bd/health"
    SLACK_WEBHOOK_URL="${SLACK_WEBHOOK_URL}"
    
    # Logging function
    log() {
        echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a /var/log/disaster-recovery.log
    }
    
    # Slack notification function
    notify_slack() {
        local message="$1"
        local color="$2"
        
        curl -X POST "$SLACK_WEBHOOK_URL" \
          -H 'Content-type: application/json' \
          --data "{
            \"attachments\": [{
              \"color\": \"$color\",
              \"title\": \"🚨 GetIt Bangladesh Disaster Recovery\",
              \"text\": \"$message\",
              \"footer\": \"Automated DR System\",
              \"ts\": $(date +%s)
            }]
          }"
    }
    
    # Health check function
    check_health() {
        local endpoint="$1"
        local timeout="${2:-10}"
        
        if curl -f -s --max-time "$timeout" "$endpoint" >/dev/null 2>&1; then
            return 0
        else
            return 1
        fi
    }
    
    # Database failover function
    failover_database() {
        log "Starting database failover..."
        
        # Promote standby to primary
        kubectl exec -n "$NAMESPACE" deployment/postgres -- \
          psql -U postgres -c "SELECT pg_promote();"
        
        # Update application configuration
        kubectl patch configmap database-config -n "$NAMESPACE" \
          -p '{"data":{"database-host":"postgres-standby"}}'
        
        # Restart applications
        kubectl rollout restart deployment/backend -n "$NAMESPACE"
        
        log "Database failover completed"
    }
    
    # Application failover function
    failover_application() {
        log "Starting application failover to secondary region..."
        
        # Switch to secondary cluster
        kubectl config use-context "$SECONDARY_CLUSTER"
        
        # Deploy applications
        kubectl apply -f /etc/kubernetes/manifests/deployments/ -n "$NAMESPACE"
        kubectl apply -f /etc/kubernetes/manifests/services/ -n "$NAMESPACE"
        
        # Wait for deployments to be ready
        kubectl wait --for=condition=ready pod -l app=backend -n "$NAMESPACE" --timeout=300s
        kubectl wait --for=condition=ready pod -l app=frontend -n "$NAMESPACE" --timeout=300s
        
        log "Application failover completed"
    }
    
    # DNS failover function
    failover_dns() {
        log "Starting DNS failover..."
        
        # Update Route53 records (requires AWS CLI configured)
        aws route53 change-resource-record-sets \
          --hosted-zone-id "$HOSTED_ZONE_ID" \
          --change-batch file:///etc/disaster-recovery/dns-failover.json
        
        log "DNS failover completed"
    }
    
    # Main failover function
    main() {
        log "Starting automated disaster recovery process..."
        
        # Verify secondary systems are healthy
        if ! check_health "https://mumbai.getit.com.bd/health"; then
            log "ERROR: Secondary region is not healthy, cannot failover"
            notify_slack "Disaster recovery failed: Secondary region unhealthy" "danger"
            exit 1
        fi
        
        # Start failover process
        notify_slack "Automated disaster recovery initiated" "warning"
        
        # 1. Database failover
        failover_database
        
        # 2. Application failover
        failover_application
        
        # 3. DNS failover
        failover_dns
        
        # 4. Verify recovery
        sleep 60  # Wait for DNS propagation
        
        if check_health "$HEALTH_ENDPOINT" 30; then
            log "Disaster recovery completed successfully"
            notify_slack "Disaster recovery completed successfully ✅" "good"
        else
            log "ERROR: Disaster recovery verification failed"
            notify_slack "Disaster recovery verification failed ❌" "danger"
            exit 1
        fi
    }
    
    # Execute main function
    main "$@"